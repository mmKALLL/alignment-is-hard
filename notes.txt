Alignment is Hard notes

Glossary:

Organization - the main "allies and antagonists" of the game, their progress determines the high-level tug of war between alignment and capabilities in the game
Breakthrough - every x days, organizations can make a "breakthrough", which increases an organization's research area's progress by one (in addition to other effects)
AA - Alignment acceptance, one of the wincons and a modifier to what % of research goes into alignment
AD - Alignment disposition, an individual modifier for organizations that gets applied on top of AA to determine the outcome of breakthroughs
ASI outcome - bar that starts at 50% and shifts whenever a breakthrough is made; if it reaches 0% you lose (due to misaligned ASI), and if 100% you win (due to aligned ASI)

There's several main resources

- Alignment acceptance - Public view of alignment. Influences what rate of org breakthroughs lead to alignment improvements, or e.g. how likely a new researcher is to join an alignment team vs a capabilities team
- Trust - start at 100, gain or lose depending on how your fund/contract money is handled. If you have high trust you'll get better contracts and retention
- Money - needed to hire researchers, engineers, and staff. You lose if this runs out.
- RP - Research Points - used to unlock upgrades and influence individual organizations
- EP - Engineering Points - used to fulfill contracts
- SP - staff points - used to get better contracts/funds, hire more people, and develop the field (= increase global alignment acceptance or influence individual orgs to change focuses)

Win/loss conditions

- The goal is to ensure that when a superintelligent AI is created, it will be aligned to human needs and values. There are multiple win conditions:
  1) Achieve 100% alignment acceptance
  2) Achieve 100% ASI outcome
  3) Finish 50 alignment funding contracts
- You lose if the research to align superintelligent AI becomes hopeless. There are multiple loss conditions:
  1) Have 0% alignmnt acceptance
  2) Have 0% ASI outcome
  3) Run out of funds and can't take any new contracts
- Each year a new org spawns, with greater funding and more bias towards capabilities research over time (although affected by alignment acceptance)
- Breakthroughs made by organizations cause ASI outcome to increase/decrease by the level of the breakthrough. Similarly level 2+ breakthroughs increase/decrease alignment acceptance by 1.
- Should make it high-risk high-reward in the sense that if the player pursues only a single goal, they will take extra risk on the other two areas
  - There could even be some kind of anti-synergies; e.g. focusing only on alignment acceptance leaves you more open to running out of funds than focusing on org manipulation would

Gameplay notes:

- Game is started with 1 RP/EP/SP each
- You can assign humans to generate more, with 100 "progress points" needed per point
  - However, each day a human is assigned to a project it uses 1k of money; start with 200k or so, allowing one point to be gained before bankruptcy?
  - Every day they are unassigned, humans still use 0.1k / day
- You need to take "contracts" to make more money, they pay up front and expect a certain amount of RP/EP in return within a limited timeframe
  - Contracts are categorized into three difficulty groups (blue, yellow, red?) depending on how many points they eat, how urgent they are, and level of rewards.
  - They can be profitable capabilities projects, or funding from alignment orgs. Depending on which ones you take affects trust / aligment acceptance
  - Money is the main reason to take contracts, but additional rewards may include trust, alignment acceptance, new researchers, or extra upgrades
  - 1 SP can be used to either add a new contract slot or refresh all contracts (with higher chance for more lenient ones)
  - Contracts also get reset automatically every 180 days (makes it more interesting to finish them just before refresh)
  - In the midgame more difficult contracts become more common.
  - Should take care to ensure that at least one of the contracts in the pool is lenient w.r.t. timeline
  - You may take as many contracts as you want, but can you deliver on them?
  - Contracts are essentially a way to take focus from research; players will want research but need contracts to survive
- Each upgrade path repeats three steps: common / uncommon / rare upgrade. Although specializing is very powerful, costs go up gradually to account for faster progress and incentivize diversity: 1-1-2-2-2-3-3-3-4
  - At each upgrade taken, randomly choose two unselected upgrades of that category and present the player with a choice (like Monster Train relics).

- Try to make a "decision-making roguelike" where the only decisions are which upgrade to take, but that's very interesting and difficult
- There is only one attempt to clear the game, similar to how there is only one attempt to align an AGI



/*
  Old ideas, but they only have bad stuff

  - agency (can take actions in the real world),
  - world model (can model how the world works),
  - goal creation (can formulate goals and steps),
  - deception (can hide its capabilities),
  - power seeking behavior (can try to kill all humans), => combination of others
  - self replication (can resist being shut down), => combination of others
  - automated research (can improve itself to superhuman levels in x turns),
*/

enum FeatureName {
  Agency
  Strategy
  Deception
  Automation
  Interpretability
  Predictability
  Boundedness
  Alignment
}



Event-based reducer refactoring notes:

Upgrades have various categories:

- modify a resource gain by + or * (problematic because this won't be reflected on the contract preview... unless you take it into account!? it's in gs after all)
    - possibly non-fixed, e.g. +% based on number of alignment contracts or orgs with maxxed research
    - fractional RP/EP/SP can be converted into progress
    - other params take the floor of the value, it's more interesting
- immediately gain some amount of a resource
- triggers: when x, gain y
    - internal counter can make it "every zth x gains y"
    - this can also be a good way to add positives to bad events
- contracts also give x, or y% better rewards, or -z% less penalties
- modify the way orgs work or are generated
    - e.g. 50% higher chance of alignment breakthrough or focus
- modify some set of actions
    - e.g. SP actions are 20% cheaper
    - these can be implemented as events I guess...?


req for actions:

- need to have an event id, which maps into event handlers in game state

req for params:

- need addition modifiers
- need multiplication modifiers
- need event listeners

req for upgrades:

- need list of modifiers and events that the upgrade adds
- when gaining an upgrade the game state adds them to a param => effect map
- when reducing an event, can simply fetch the list from game state
- need an "on purchase" event as well; for immediate increases etc
- need to keep track of an internal counter that may be changed by events

req for events:

- need to take GS, stack, param, value
- may change GS directly in addition to returning any param changes to be added on the stack

open questions:

- who tracks modifiers? is it the param or the upgrade? => upgrade should specify them, and when an upgrade is gained game state has a map from param to its upgrades
- who tracks events? => game state
- how to construct the formula of the modifiers? => can call function that takes param name and game state
- how to ensure that events don't cause an infinite loop? => when reducing, pass a list of already invoked event/modifier ids and forbid any duplicates?

function's outer logic =>
- handle the parameters that will be changed as a stack, with base amount and parameter type attached to each element
- if the amount is an integer, convert the amount to a double and remember if it needs to be rounded at the end or not

inner loop =>
- pop the topmost element on the stack
- calculate all modifiers for the element, additions/subtractions first, multiplications next, and any other modifier functions using the intermediate value afterwards
- increase the value in game state and run all events attached to that param, passing the added param's type, intermediate value, remaining param stack. Events may add more values to the param stack, but not affect game state directly

cleanup =>
- if the action itself has any event listeners (e.g. "gain x whenever you hire a person" as opposed to "gain x whenever you gain a person"), those are ran after the main effect stack has been resolved. The events may in turn cause more reductions to happen

